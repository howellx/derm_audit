#!/usr/bin/env python
import torch
import numpy as np
from tqdm import tqdm

def kid_ebpe(dataloader, generator, detector, indices=[0,9], max_images=50000,
        num_subsets=100, max_subset_size=1000, device='cuda'):
    __doc__ = """Estimate the Kernel Inception Distance between a distribution 
    of real images and the distribution of images generated by the generator.

    Args:
      dataloader: (torch.utils.data.DataLoader) A dataloader instance that
        generates both images and labels. The images will be used as inputs
        directly to the detector and generator. Images should 
      generator: (torch.nn.Module) The generator model. Should accept a batch
        of images and batch of target classes (integers) as an input. 
      detector: (torch.nn.Module) An instance of the pretrained InceptionV3 
        model used to extract features.
      indices: (List) A list of integers denoting the generator's target classes
        that should be used when calculating the KID.
      max_images: (int) The maximum number of images to use when calculating the
        KID.
      num_subsets: (int) The number of subsets to use when estimating the KID,
        which is the squared maximum mean discrepency between the real and 
        generated distributions (see Bi/'nkowski et al. for complete 
        information).
      max_subset_size: (int) The maximum size of a subset to use in the 
        estimate.
    """
    real_features = []
    gen_features = []
    detector.to(device)
    generator.to(device)
    image_count = 0
    for ibatch, batch in enumerate(tqdm(dataloader, total=len(dataloader))):
        img, label = batch
        image_count += img.shape[0]
        if image_count > max_images:
            break
        img = img.to(device)
        img_int = img.to(torch.int32)
        # Use target classes selected at random from `indices`.
        targets = np.random.choice(indices, img.shape[0], replace=True)
        targets = torch.Tensor(targets).to(torch.int32).to(device)
        with torch.no_grad():
            real_features.append(detector(img_int).detach().cpu().numpy())
            gen_features.append(detector(generator(img, targets)).detach().cpu().numpy())
    real_features = np.concatenate(real_features)
    gen_features = np.concatenate(gen_features)
    return kid(real_features, 
               gen_features, 
               num_subsets=num_subsets, 
               max_subset_size=max_subset_size)

def kid(real_features, gen_features, num_subsets=100, max_subset_size=1000):
    __doc__ = """Estimate the Kernel Inception Distance between the real data
    distribution and the distribution generated by the generator.

    KID was originally proposed by Bi\'nkowski, Sutherland, Arbel, and
    Gretton in "Demystifying MMD GANs" (ICLR 2018). This implementation is based
    on the NVLabs' implementation at:
    https://github.com/NVlabs/stylegan2-ada-pytorch.

    Args:
      real_features: (torch.Tensor) Tensor of features computed as the
        activations of the penultimate layer of a pretrained Inception-V3 
        network when evaluated on samples from the real data distribution.
      gen_features: (torch.Tensor) Tensor of features computed as the
        activations of the penultimate layer of a pretrained Inception-V3 
        network when evaluated on samples from the generator's distribution.
      num_subsets: (int) The number of subsets to use when estimating the KID,
        which is the squared maximum mean discrepency between the real and 
        generated distributions (see Bi/'nkowski et al. for complete 
        information).
      max_subset_size: (int) The maximum size of a subset to use in the 
        estimate.
        
    Returns:
      kid: (float) An unbiased estimate of the kernel inception distance."""
    n_features = real_features.shape[1]
    subset_size = min(real_features.shape[0], gen_features.shape[0], max_subset_size)
    t = 0
    for i_subset in range(num_subsets):
        x = gen_features[np.random.choice(gen_features.shape[0], subset_size, replace=False)]
        y = real_features[np.random.choice(real_features.shape[0], subset_size, replace=False)]
        a = (x @ x.T / n_features + 1) ** 3 + (y @ y.T / n_features + 1) ** 3
        b = (x @ y.T / n_features + 1) ** 3
        t += (a.sum() - np.diag(a).sum()) / (subset_size - 1) - b.sum() * 2 / subset_size
    kid = t/(num_subsets*subset_size)
    return float(kid)




